{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqpkwL9_vOjK"
      },
      "outputs": [],
      "source": [
        "# 코랩에서 작동 O / vscode에서는 모르겠음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBMWFyPXM1un",
        "outputId": "7dc23c61-202b-4bf1-9e6a-cddc5244c8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_xiyz9FvF-8",
        "outputId": "8c7abb40-78e3-490b-9295-312de3f37354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "orbax-checkpoint 0.4.4 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rhLFSTmF3F5",
        "outputId": "8eebc979-1e7c-45ff-92ee-39a533e98c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m897.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=7d210d9b4246ddce46b74d42e05f3c512cb5aea3ced39352f507015c6cc82f8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lbIrKqXPcNpk"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import pandas as pd\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JkV3WFpf-EE0"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGFNGuOjvAq4",
        "outputId": "027bb51d-8a34-4852-ea13-ab34bf97ac46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: 안녕하세요! 친구 이름님을 위한 선물을 준비하고 있는 사람이 있어요. 어떤 종류의 선물을 원하시나요? 예를 들어 음악, 여행, 요리 등 다양한 분야가 있으니까요. 어떤 물건이 가장 원하시는지 알려주세요!\n",
            "Assistant: 바지가 좋으시군요! 특별히 원하시는 스타일이 있으신가요? 여유 있게 말씀해주세요!\n",
            "Assistant: 네, 파란색이 좋으시고 빨간색은 싫으시군요! 나이키 제품이 좋으시고 아디다스 제품은 싫으시군요! 귀하의 소중한 의견 감사합니다!\n"
          ]
        }
      ],
      "source": [
        "# 사용자 이름 설정\n",
        "user_name = \"친구 이름\"  # 여기에 실제 친구 이름 입력\n",
        "\n",
        "# 첫 번째 메시지 정의 및 출력\n",
        "initial_message = f\"안녕하세요! {user_name}님을 위한 선물을 준비하고 있는 사람이 있어요. 어떤 종류의 선물을 원하시나요? 예를 들어 음악, 여행, 요리 등 다양한 분야가 있으니까요. 어떤 물건이 가장 원하시는지 알려주세요!\"\n",
        "print(f\"Assistant: {initial_message}\")\n",
        "\n",
        "# 대화 기록을 저장할 리스트 초기화\n",
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"누군가에게 선물을 주기 위해 그 사람의 취향을 알아보려고 해. 하지만 선물 받는 당사자에게 직접 물어보기 어려워서 너를 이용해서 익명으로 선물을 받는 상대에게 물어보려고 해. 너는 상대방에게 구체적으로 어떤 취향을 갖고 있는지 물어보고, 취향을 파악해주는 조수야. 너는 상대방의 이름, 나이를 알고 있어. 제일 첫 대화는 인사와 함께 상대방에게 갖고 싶은 물건이 있는 물어봐줘야 해. 누군가가 상대방을 위해 선물을 준비하고 있다는 사실을 알려줘. 상대방에게 답변이 오면 구체적인 품목에 대한 선호도 질문을 해야해. 상대방이 이미 선호하는 품목을 언급했다면, 그 품목에 대해 더 자세히 물어볼 수 있어. 최대 3문장으로 말해줘.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": initial_message\n",
        "    }\n",
        "]\n",
        "\n",
        "while True:\n",
        "    # 사용자의 입력 받기\n",
        "    user_input = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # 대화 기록에 사용자의 입력 추가\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # 챗봇에게 대화 전달 및 응답 받기\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"ft:gpt-3.5-turbo-1106:personal::8c5qJUIG\",\n",
        "        messages=conversation,\n",
        "        max_tokens=150,\n",
        "        temperature=0.4,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    # 챗봇의 응답을 대화 기록에 추가 및 출력\n",
        "    assistant_response = response.choices[0].message.content\n",
        "    print(f\"Assistant: {assistant_response}\")\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmt6Sk1EM3EJ",
        "outputId": "13cb03e8-ab41-45d3-f18c-e123c6994604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "사용자는 선물로 바지를 원하며, 파란색을 선호하고 빨간색을 싫어하며, 나이키 제품을 좋아하고 아디다스 제품을 싫어합니다.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"사용자의 대화 내용에서 핵심적인 선호도를 파악하고 이를 간결하게 요약해주세요. 선물 준비와 관련된 맥락은 제외하고, 사용자가 언급한 구체적인 선호도(예: 브랜드, 색상, 제품 유형)만을 중심으로 요약합니다.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": str(conversation)\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=1000,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "summarization = response.choices[0].message.content\n",
        "\n",
        "print(summarization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5FLT5KhR51p",
        "outputId": "88247672-5def-4829-b711-83546ae80bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "긍정적인 명사: 바지, 파란색, 나이키 제품\n",
            "부정적인 명사: 빨간색, 아디다스 제품\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"당신은 문장에서 각 명사가 긍정적인지 부정적인지 분리해주는 똑똑한 사람입니다. \\\n",
        "                문장의 맥락을 고려해 긍정적인 명사와 부정적인 명사로 정확하게 분류하고 출력해주세요. \\\n",
        "                '긍정적인 명사:  부정적인 명사: ' 이런 형태로 출력해줘, 선물이란 단어는 빼줘\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": summarization\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=1000,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "responses = response.choices[0].message.content\n",
        "\n",
        "print(responses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qrxqC43sZXf",
        "outputId": "21716884-bf33-4fc3-aae6-705cd7b28d26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['바지', '파란색', '나이키 제품']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the response into parts and then extract the positive nouns\n",
        "parts = responses.split('\\n')\n",
        "positive_part = parts[0]  # Assuming the first line contains the positive nouns\n",
        "positive_nouns_string = positive_part.split(': ')[1]  # Splitting by ': ' to get the list after '긍정적인 명사: '\n",
        "positive_nouns = positive_nouns_string.split(', ')  # Splitting by ', ' to get individual nouns\n",
        "\n",
        "positive_nouns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avBxpPESIBFT",
        "outputId": "e967d3c4-0ec4-4726-c076-0402bff845d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['빨간색', '아디다스 제품']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 응답 문자열을 줄 단위로 분리\n",
        "parts = responses.split('\\n')\n",
        "\n",
        "# 부정적인 명사가 포함된 줄 찾기 (예: \"부정적인 명사: 나이키\")\n",
        "negative_part = next(part for part in parts if part.startswith(\"부정적인 명사\"))\n",
        "\n",
        "# ':' 기호 뒤의 텍스트를 추출하여 부정적인 명사 리스트 생성\n",
        "negative_nouns_string = negative_part.split(': ')[1]\n",
        "negative_nouns = negative_nouns_string.split(', ')\n",
        "\n",
        "negative_nouns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rpCuvsOpVDQ",
        "outputId": "945d45e7-ff11-4101-b21b-6604c8c35a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "긍정적인 명사 리스트: ['바지', (0, 0, 255), '나이키 제품']\n",
            "부정적인 명사 리스트: [(255, 0, 0), '아디다스 제품']\n"
          ]
        }
      ],
      "source": [
        "# 색상 이름과 해당하는 RGB 코드를 매핑한 딕셔너리\n",
        "colors_rgb = {\n",
        "    \"빨간색\": (255, 0, 0),       # 빨간색의 RGB 코드\n",
        "    \"빨강\": (255, 0, 0),       # 빨간색의 RGB 코드\n",
        "    \"주황색\": (255, 165, 0),     # 주황색의 RGB 코드\n",
        "    \"노란색\": (255, 255, 0),     # 노란색의 RGB 코드\n",
        "    \"노랑\": (255, 255, 0),     # 노란색의 RGB 코드\n",
        "    \"초록색\": (0, 128, 0),       # 초록색의 RGB 코드\n",
        "    \"파란색\": (0, 0, 255),       # 파란색의 RGB 코드\n",
        "    \"남색\": (0, 0, 128),         # 남색의 RGB 코드\n",
        "    \"네이비\": (0, 0, 128),         # 남색의 RGB 코드\n",
        "    \"보라색\": (128, 0, 128),     # 보라색의 RGB 코드\n",
        "    \"흰색\": (255, 255, 255),     # 흰색의 RGB 코드\n",
        "    \"베이지\" : (245,245,220),     # 베이지색의 RGB 코드\n",
        "    \"검정색\": (0, 0, 0),         # 검정색의 RGB 코드\n",
        "    \"검은색\": (0, 0, 0),         # 검정색의 RGB 코드\n",
        "    \"회색\": (128,128,128),         # 회색의 RGB 코드\n",
        "    \"갈색\": (139, 69, 19),       # 갈색의 RGB 코드\n",
        "    \"분홍색\": (255, 192, 203)    # 분홍색의 RGB 코드\n",
        "}\n",
        "\n",
        "# 긍정적인 명사 리스트를 색상 이름에서 RGB 코드로 변환\n",
        "converted_positive = [colors_rgb[noun] if noun in colors_rgb else noun for noun in positive_nouns]\n",
        "\n",
        "# 부정적인 명사를 색상 RGB 코드로 변환\n",
        "converted_negative = [colors_rgb[noun] if noun in colors_rgb else noun for noun in negative_nouns]\n",
        "\n",
        "print(\"긍정적인 명사 리스트:\", converted_positive)\n",
        "print(\"부정적인 명사 리스트:\", converted_negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "dYj4SefTbdik"
      },
      "outputs": [],
      "source": [
        "matching = []\n",
        "negative = []\n",
        "positive_colors = []\n",
        "negative_colors = []\n",
        "for i in converted_positive:\n",
        "  if type(i) == str:\n",
        "    matching.append(i)\n",
        "  elif type(i) == tuple:\n",
        "    positive_colors.append(i)\n",
        "for i in converted_negative:\n",
        "  if type(i) == str:\n",
        "    negative.append(i)\n",
        "  elif type(i) == tuple:\n",
        "    negative_colors.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1BvfPAiob0TP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data3 = pd.read_json('all_data_embed.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import ast\n",
        "# data3['text'] = data3['text'].apply(lambda x: ast.literal_eval(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "vCp6VDWvJ3M6",
        "outputId": "c9f87376-2e60-4265-91fa-2a3724b2aac5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# 자신의 드라이브 형식에 맞게 파일 읽\n",
        "with open('sentencetransformer.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nEhlyL86RDfk"
      },
      "outputs": [],
      "source": [
        "matching_embed = []\n",
        "for i in matching:\n",
        "  i_embed = loaded_model.encode(i)\n",
        "  matching_embed.append(i_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_number(s):\n",
        "    \"\"\" 문자열이 부동 소수점 숫자 형식인지 확인 \"\"\"\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "sex = True\n",
        "min_price = 10000\n",
        "max_price = 100000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>name</th>\n",
              "      <th>grade</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2146</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>인디안 [겨울특가] 남성 밍크본딩 인디고 청바지_NIUDLYW9581SSS_터미널</td>\n",
              "      <td>4.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2199</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>[1+1] WFD087기모패딩바지 기모 솜바지 따뜻한 방</td>\n",
              "      <td>4.5</td>\n",
              "      <td>59.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>['유아동/완구', '신생아/유아패션', '바지/레깅스']</td>\n",
              "      <td>[20%↓DOWN PRICE]레꼴트레이닝팬츠_BP33PD31</td>\n",
              "      <td>5.0</td>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2184</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>인디안 [겨울특가] 남성 체크 프린트 본딩 원턱 바지_NITDLYWA131SSS_터미널</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2641</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>인디안 [겨울특가] 남성 스트레치 기모 블랙 청바지_NIUDLYW9561SSS_터미널</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2349</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>트레몰로 (주)세정 이월 FW인디고 뒷면기모 겨울데님청바지 TRNDLYW9571_동...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2320</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>남성 밑위가 긴 사방스판 기모 청바지 HS-JEK-7012-네이</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2526</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>남자 오토바이 방한 패딩 바지 라이더 팬츠 선</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2178</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '셔츠/남방']</td>\n",
              "      <td>남자 오토바이 방한 패딩 바지 라이더 팬츠 선</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2257</th>\n",
              "      <td>['패션/언더웨어', '남성의류', '팬츠']</td>\n",
              "      <td>인디안 [겨울특가] 남성 솔리드 기모 바지_NITDLYW9541SSS_터미널</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              category  \\\n",
              "2146         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "2199         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "282   ['유아동/완구', '신생아/유아패션', '바지/레깅스']   \n",
              "2184         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "2641         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "2349         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "2320         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "2526         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "2178      ['패션/언더웨어', '남성의류', '셔츠/남방']   \n",
              "2257         ['패션/언더웨어', '남성의류', '팬츠']   \n",
              "\n",
              "                                                   name  grade  score  \n",
              "2146      인디안 [겨울특가] 남성 밍크본딩 인디고 청바지_NIUDLYW9581SSS_터미널    4.0   61.0  \n",
              "2199                    [1+1] WFD087기모패딩바지 기모 솜바지 따뜻한 방    4.5   59.5  \n",
              "282                   [20%↓DOWN PRICE]레꼴트레이닝팬츠_BP33PD31    5.0   57.0  \n",
              "2184   인디안 [겨울특가] 남성 체크 프린트 본딩 원턱 바지_NITDLYWA131SSS_터미널    0.0   56.0  \n",
              "2641    인디안 [겨울특가] 남성 스트레치 기모 블랙 청바지_NIUDLYW9561SSS_터미널    0.0   56.0  \n",
              "2349  트레몰로 (주)세정 이월 FW인디고 뒷면기모 겨울데님청바지 TRNDLYW9571_동...    0.0   56.0  \n",
              "2320                남성 밑위가 긴 사방스판 기모 청바지 HS-JEK-7012-네이    0.0   56.0  \n",
              "2526                          남자 오토바이 방한 패딩 바지 라이더 팬츠 선    0.0   56.0  \n",
              "2178                          남자 오토바이 방한 패딩 바지 라이더 팬츠 선    0.0   56.0  \n",
              "2257         인디안 [겨울특가] 남성 솔리드 기모 바지_NITDLYW9541SSS_터미널    0.0   56.0  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from sentence_transformers import util\n",
        "\n",
        "def calculate_score_improved(row, matching, matching_embed, negative, positive_colors, negative_colors, sex, min_price, max_price):\n",
        "    # 숫자를 문자열로 변환\n",
        "    category1 = str(row['category1'])\n",
        "    category2 = str(row['category2'])\n",
        "    category3 = str(row['category3'])\n",
        "    name = str(row['name'])\n",
        "\n",
        "    # 부정적 요소가 있는 경우 점수 계산 제외\n",
        "    for neg in negative:\n",
        "        if neg in category1 or neg in category2 or neg in category3 or neg in name:\n",
        "            return None\n",
        "    \n",
        "    if len(negative_colors) != 0:\n",
        "        for neg_color in negative_colors:\n",
        "            neg_red = abs(row['R'] - neg_color[0])\n",
        "            neg_green = abs(row['G'] - neg_color[1])\n",
        "            neg_blue = abs(row['B'] - neg_color[2])\n",
        "            if max(neg_red, neg_green, neg_blue) <= 64:\n",
        "                return None\n",
        "            elif sum([neg_red, neg_green, neg_blue]) <= 128:\n",
        "                return None\n",
        "\n",
        "    # 긍정적 요소 점수 계산\n",
        "    score = 0\n",
        "    for j in matching:\n",
        "        if j in category1 or j in category2 or j in category3:\n",
        "            score += 1\n",
        "        elif j in name:\n",
        "            score += 1\n",
        "\n",
        "    for word, word_embed in zip(matching, matching_embed):\n",
        "        # word_embed를 텐서로 변환 및 차원 조정\n",
        "        if not isinstance(word_embed, torch.Tensor):\n",
        "            word_embed = torch.tensor(word_embed, dtype=torch.float)\n",
        "        word_embed = word_embed.view(1, -1)\n",
        "\n",
        "        cos_sim_total = 0\n",
        "        for emb_str in row['embed']:\n",
        "            # emb가 문자열인 경우 숫자 배열로 변환\n",
        "            if isinstance(emb_str, str):\n",
        "                emb_list = emb_str.strip(\"[]\").split(',')\n",
        "                emb = [float(num) for num in emb_list if is_number(num)]\n",
        "                emb = torch.tensor(emb, dtype=torch.float)\n",
        "            elif isinstance(emb_str, torch.Tensor):\n",
        "                emb = emb_str\n",
        "            else:\n",
        "                continue  # emb가 문자열이나 텐서가 아닌 경우\n",
        "\n",
        "            # 빈 텐서 확인 및 차원 조정\n",
        "            if emb.nelement() == 0:\n",
        "                continue\n",
        "            if len(emb.shape) == 1:\n",
        "                emb = emb.view(1, -1)\n",
        "\n",
        "            # word_embed와 emb의 차원이 일치하는지 확인\n",
        "            if word_embed.shape[1] != emb.shape[1]:\n",
        "                continue\n",
        "\n",
        "            cos_sim_ten = util.pytorch_cos_sim(word_embed, emb)\n",
        "            cos_sim = cos_sim_ten.numpy()[0][0]\n",
        "            if cos_sim > cos_sim_total:\n",
        "                cos_sim_total = cos_sim\n",
        "        score += cos_sim_total\n",
        "\n",
        "    total = 100 * (score / len(matching))\n",
        "\n",
        "    if positive_colors == []:\n",
        "        min_color_diff = 0\n",
        "    else:\n",
        "        # 색상 차이 계산\n",
        "        min_color_diff = float('inf')\n",
        "        for color in positive_colors:\n",
        "            pos_red = abs(row['R'] - color[0])\n",
        "            pos_green = abs(row['G'] - color[1])\n",
        "            pos_blue = abs(row['B'] - color[2])\n",
        "            if max(pos_red, pos_green, pos_blue) <= 64:\n",
        "                min_color_diff = 0\n",
        "            elif sum([pos_red, pos_green, pos_blue]) <= 128:\n",
        "                min_color_diff = 0\n",
        "            color_diff = pos_red + pos_green + pos_blue\n",
        "            min_color_diff = min(min_color_diff, color_diff)\n",
        "\n",
        "    # 가장 작은 색상 차이를 30으로 나눈 값을 점수에서 감점\n",
        "    total -= min_color_diff // 30\n",
        "    # 'grade' 추가 점수 (현재 주석 처리됨)\n",
        "    total += row['grade']\n",
        "    if sex:\n",
        "        pos_sex = \"남성\"\n",
        "        neg_sex = \"여성\"\n",
        "    else:\n",
        "        pos_sex = \"여성\"\n",
        "        neg_sex = \"남성\"\n",
        "    if str(pos_sex) in category1 or str(pos_sex) in category2 or str(pos_sex) in category3:\n",
        "        total += 5\n",
        "    elif str(pos_sex) in name:\n",
        "        total += 5\n",
        "    if str(neg_sex) in category1 or str(neg_sex) in category2 or str(neg_sex) in category3:\n",
        "        total -= 5\n",
        "    elif str(neg_sex) in name:\n",
        "        total -= 5\n",
        "        \n",
        "    if row['price'] >= min_price and row['price'] <= max_price:\n",
        "        total += 10\n",
        "\n",
        "    return total\n",
        "\n",
        "# DataFrame에 함수 적용\n",
        "data3['score'] = data3.apply(lambda row: calculate_score_improved(row, matching, matching_embed, negative, positive_colors, negative_colors, sex, min_price, max_price), axis=1)\n",
        "\n",
        "# 결과 정렬 및 출력\n",
        "data3_sorted = data3.sort_values(by='score', ascending=False)\n",
        "data3_sorted[['category', 'name', 'grade', 'score']].head(10)\n",
        "# data3_sorted.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
